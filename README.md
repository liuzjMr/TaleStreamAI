# AI å°è¯´æ¨æ–‡è‡ªåŠ¨åŒ–å·¥ä½œæµ

[æˆç‰‡-6å°æ—¶](https://www.bilibili.com/video/BV1mmQvYEEwb/)
[çˆ±å‘ç”µ](https://afdian.com/a/dmzw1918)

## é¡¹ç›®ç»“æ„

```
.
â”œâ”€â”€ app
â”œâ”€â”€ data
â”‚   â”‚â”€ book
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## é¡¹ç›®ä½¿ç”¨åˆ°çš„å¤§æ¨¡å‹

-   DeepSeek-V3
-   gemini-2.0-flash
-   ç¡…åŸºæ™ºèƒ½-FunAudioLLM/CosyVoice2-0.5B
-   ç§‹è‘‰ aaaki forge æ•´åˆåŒ…

## é¡¹ç›®æµç¨‹

| æ–‡ä»¶å       | åŠŸèƒ½           | æ¨¡å‹/åº“                  |
| ------------ | -------------- | ------------------------ |
| main.py      | è·å–ä¹¦ç±å†…å®¹   | æ—                        |
| board.py     | ç”Ÿæˆç« èŠ‚åˆ†é•œ   | gemini-2.0-flash         |
| prompt.py    | æ¶¦è‰²åˆ†é•œæç¤ºè¯ | deepseek-v3              |
| image.py     | ç”Ÿæˆå›¾ç‰‡       | ç§‹è‘‰ aaaki forge ç‰ˆ      |
| audio.py     | ç”ŸæˆéŸ³é¢‘       | CosyVoice2-0.5B:benjamin |
| tts.py       | ç”Ÿæˆå­—å¹•       | æœ¬åœ°è¿è¡Œ whisper         |
| video.py     | ç”Ÿæˆè§†é¢‘       | ffmpeg-gpu åŠ é€Ÿç‰ˆ        |
| video_end.py | ç”Ÿæˆå®Œæ•´è§†é¢‘   | ffmpeg-gpu åŠ é€Ÿç‰ˆ        |

## æœ¬åœ°è¿è¡Œ

> æœ¬é¡¹ç›®ä½¿ç”¨çš„æ˜¯`uv`æ¥ç®¡ç†ä¾èµ–,å»ºè®® python ç‰ˆæœ¬`>=3.10`

1. å®‰è£…`uv`

```shell
pip install uv
```

2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```shell
uv venv --python 3.12
```

```sh
    .\.venv\Scripts\activate
```

3. å®‰è£…åŒ…

```shell
uv add -r requirements.txt
```

4. å®‰è£… torch ç¯å¢ƒ
    > torch ç¯å¢ƒè¯·æ ¹æ®ä½ ç³»ç»Ÿçš„ cuda ç‰ˆæœ¬æ¥å®‰è£… [torch å®˜ç½‘](https://pytorch.org/)

```sh
uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

å¯ä»¥é€šè¿‡`nvidia-smi`æ¥æŸ¥è¯¢ä½ çš„æ˜¾å¡æ”¯æŒçš„æœ€é«˜`cuda`ç‰ˆæœ¬

```sh
nvidia-smi
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.94                 Driver Version: 560.94         CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 4070 Ti   WDDM  |   00000000:01:00.0  On |                  N/A |
|  0%   28C    P8              4W /  285W |    2157MiB /  12282MiB |      2%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
```

é€šè¿‡ `nvcc` æ¥æŸ¥è¯¢ä½ ç”µè„‘å·²å®‰è£…çš„`cuda`ç‰ˆæœ¬

> å…¶å®æ˜¯ä½ ç¯å¢ƒå˜é‡ä¸­é…ç½®çš„ç‰ˆæœ¬è€Œå·²ï¼Œä¸€ä¸ªç”µè„‘ä¸Šå¯ä»¥å®‰è£…å¤šä¸ª cuda

```sh
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2022 NVIDIA Corporation
Built on Wed_Sep_21_10:41:10_Pacific_Daylight_Time_2022
Cuda compilation tools, release 11.8, V11.8.89
Build cuda_11.8.r11.8/compiler.31833905_0
```

## ç¯å¢ƒé…ç½®

å¤åˆ¶ `.env.example` æ–‡ä»¶ï¼Œæ”¹åä¸º `.env`  
é…ç½®å…¶ç¼ºå°‘çš„ APIKey  
å…¶ä¸­ `AUDIO_API_KEY` æ˜¯å¯ä»¥æ”¯æŒå¤š Key è½®è¯¢çš„ï¼Œç”¨`,`åˆ†å‰²  
(åšåˆ°è¿™ä¸€æ­¥æˆ‘æ‰æ„è¯†åˆ°å¯ä»¥å¤š Key æ”¯æŒé«˜å¹¶å‘ ğŸ˜‚ å¦‚æœéœ€ Gemini éœ€è¦é«˜å¹¶å‘çš„è¯ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨å» copy å¤š key çš„å¤„ç†çš„ä»£ç åˆ°`board.py`ä¸­äº†)   
é…ç½®`èµ·ç‚¹è¾¾äººä¸­å¿ƒ`çš„ Cookie ç”¨æ¥æŠ“å–å°è¯´ [èµ·ç‚¹è¾¾äººä¸­å¿ƒ](https://koc.yuewen.com/home)  
å®‰è£…`ffmpeg`æœ€å¥½å®‰è£…GPUåŠ é€Ÿç‰ˆï¼Œå¦åˆ™ç”Ÿæˆçš„å¾ˆæ…¢(å¥½åƒæ–°ä¸€ç‚¹çš„ç‰ˆæœ¬éƒ½å·²ç»æ”¯æŒgpuåŠ é€Ÿäº†) [Github](https://github.com/BtbN/FFmpeg-Builds/releases)  
ä½¿ç”¨ `ffmpeg -hwaccels` æ¥åˆ—å‡ºç¡¬ä»¶åŠ é€Ÿé€‰é¡¹
```sh
Hardware acceleration methods:
cuda
vaapi
dxva2
qsv
d3d11va
opencl
vulkan
```

## è¿è¡Œé¡¹ç›®

æˆ‘æ˜¯ç›´æ¥æŒ‰ç…§é¡¹ç›®æµç¨‹æ¥é€ä¸ªè¿è¡Œæ–‡ä»¶çš„ 

```sh
uv run app/main.py     # è·å–å°è¯´å†…å®¹
uv run board.py    # ç”Ÿæˆåˆ†é•œ
uv run prompt.py   # ä¼˜åŒ–æç¤ºè¯
uv run image.py    # ç”Ÿæˆå›¾ç‰‡
uv run audio.py    # åˆæˆéŸ³é¢‘  
uv run tts.py      # ç”Ÿæˆå­—å¹•
uv run video.py    # åˆ¶ä½œåˆ†é•œè§†é¢‘
uv run video_end.py # æœ€ç»ˆåˆæˆ
```

å¦‚æœä½ æƒ³è¦ç›´æ¥è¿è¡Œ ä¹Ÿå¯ä»¥ç›´æ¥è¿è¡Œ main.py
```sh
uv run main.py
```

## Whisper æ¨¡å‹è§„æ ¼æ¦‚è§ˆ

Whisper æ¨¡å‹è§„æ ¼
| æ¨¡å‹è§„æ ¼ | å‚æ•°é‡ | æœ€ä½æ˜¾å­˜è¦æ±‚ |
|---------|-------|------------|
| Tiny | 39M | ~1GB |
| Base | 74M | ~1GB |
| Small | 244M | ~2GB |
| Medium | 769M | ~5GB |
| Large | 1550M | ~10GB |
| Large-v2| 1550M | ~10GB |
| Large-v3| 1550M | ~10GB |

3. **è¿è¡Œç¤ºä¾‹ä»£ç **
å¯ä»¥å…ˆå†™ä¸ªæµ‹è¯•ï¼Œè¿è¡Œç¤ºä¾‹ä»£ç æ¥ä¸‹è½½ Whisper
```python
import torch
from transformers import WhisperProcessor, WhisperForConditionalGeneration

# é€‰æ‹©é€‚åˆæ‚¨æ˜¾å­˜çš„æ¨¡å‹å¤§å°ï¼Œä¾‹å¦‚"medium"
model_id = "openai/whisper-medium"

# å¯ç”¨åŠç²¾åº¦ä»¥èŠ‚çœæ˜¾å­˜
processor = WhisperProcessor.from_pretrained(model_id)
model = WhisperForConditionalGeneration.from_pretrained(
    model_id,
    torch_dtype=torch.float16,
    device_map="auto"
)

# ç¡®ä¿æ¨¡å‹åœ¨GPUä¸Šè¿è¡Œ
device = "cuda" if torch.cuda.is_available() else "cpu"
model = model.to(device)
```
